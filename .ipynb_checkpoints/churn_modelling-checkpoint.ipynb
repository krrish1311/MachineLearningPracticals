{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we have to create a model for churn ratio. \n",
    "# Which factor depends on the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "y=df[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Gender & Geography for now to do one hot encoding \n",
    "X=df.drop(['Exited','RowNumber','CustomerId','Surname','Gender','Geography'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  \n",
       "0               1        101348.88  \n",
       "1               1        112542.58  \n",
       "2               0        113931.57  \n",
       "3               0         93826.63  \n",
       "4               1         79084.10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, Geography nd Gender are categorical variable, so do one hot encoding \n",
    "geo=df['Geography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to remove one column for preventing dummy variable trap. \n",
    "geo = pd.get_dummies(geo,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding --> Gender variable\n",
    "gen=df[\"Gender\"]\n",
    "gen = pd.get_dummies(gen,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "9995     1\n",
       "9996     1\n",
       "9997     0\n",
       "9998     1\n",
       "9999     0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now concatenating gender, geography and x\n",
    "X_final=pd.concat([X,gen,geo],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Male  Germany  Spain  \n",
       "0                  1        101348.88     0        0      0  \n",
       "1                  1        112542.58     0        0      1  \n",
       "2                  0        113931.57     0        0      0  \n",
       "3                  0         93826.63     0        0      0  \n",
       "4                  1         79084.10     0        0      1  \n",
       "...              ...              ...   ...      ...    ...  \n",
       "9995               0         96270.64     1        0      0  \n",
       "9996               1        101699.77     1        0      0  \n",
       "9997               1         42085.58     0        0      0  \n",
       "9998               0         92888.52     1        1      0  \n",
       "9999               0         38190.78     0        0      0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split data into training and testing \n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train,X_test,y_train,y_test=tts(X_final,y,test_size=0.2,random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Keras model \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1st layer with 8 neurons\n",
    "# We have 11 features to be provided so input_dim=11\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8, input_dim=11, activation=\"relu\", kernel_initializer=\"zeros\", bias_initializer=\"zeros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd layer \n",
    "model.add(Dense(units=8, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add final layer with sigmoid function as output can be 1 or 0\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt=Adam(learning_rate=0.0000000005)\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 12s 897us/step - loss: 0.6758\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 926us/step - loss: 0.6172\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.5744\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 877us/step - loss: 0.5510\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 869us/step - loss: 0.5342\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 934us/step - loss: 0.5119\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 914us/step - loss: 0.5128\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 897us/step - loss: 0.5200\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 894us/step - loss: 0.4952\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.5020\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.5012\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 906us/step - loss: 0.4985\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.5013\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.5108\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.4996\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.4990\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 910us/step - loss: 0.5053\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.4890\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.5028\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.4929\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 905us/step - loss: 0.5007\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 906us/step - loss: 0.4993\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 901us/step - loss: 0.4941\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 937us/step - loss: 0.5029\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 897us/step - loss: 0.4990\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 901us/step - loss: 0.4983\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.5038\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.5041\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 934us/step - loss: 0.5082\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.5006\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 901us/step - loss: 0.4937\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 906us/step - loss: 0.4935\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5042\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.4941\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 918us/step - loss: 0.5085\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 922us/step - loss: 0.4987\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 910us/step - loss: 0.5002\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 942us/step - loss: 0.4979\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.5041\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.5049\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.5005\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 933us/step - loss: 0.5014\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 949us/step - loss: 0.5027\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 922us/step - loss: 0.5072\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 914us/step - loss: 0.4930\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 918us/step - loss: 0.5038\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 946us/step - loss: 0.4985\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 910us/step - loss: 0.5009\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 922us/step - loss: 0.4870\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 918us/step - loss: 0.4979\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 901us/step - loss: 0.4995\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 934us/step - loss: 0.4939\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.5095\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.5035\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.5026\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.4984\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 933us/step - loss: 0.5003\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 970us/step - loss: 0.5032\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 918us/step - loss: 0.4934\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 994us/step - loss: 0.5049\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 945us/step - loss: 0.5029\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 949us/step - loss: 0.4932\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 942us/step - loss: 0.5010\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.4969\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.5068\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 941us/step - loss: 0.4975\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 957us/step - loss: 0.4919\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 946us/step - loss: 0.5014\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 990us/step - loss: 0.5076\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 945us/step - loss: 0.4991\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.4982\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.5025\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.5085\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.4983\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 966us/step - loss: 0.4845 0s - loss: 0.47\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.4977\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.5057\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4996\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5068\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.5030\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 938us/step - loss: 0.5044\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4942\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 933us/step - loss: 0.5020\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 934us/step - loss: 0.5036\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 962us/step - loss: 0.4973\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 982us/step - loss: 0.5046\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.4992\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.4938\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.4956\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.4995\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.4954\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.5080\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.5039\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 957us/step - loss: 0.5025\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 978us/step - loss: 0.4976\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4997\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 929us/step - loss: 0.4971\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 889us/step - loss: 0.5048\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 921us/step - loss: 0.5087\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.5086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7b6a39970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just by adding Learning Rate, we can see sudden change in loss. \n",
    "model.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6598536372184753,\n",
       "  0.6062511205673218,\n",
       "  0.5687851309776306,\n",
       "  0.5430914163589478,\n",
       "  0.526042640209198,\n",
       "  0.5152000188827515,\n",
       "  0.5084578394889832,\n",
       "  0.5043415427207947,\n",
       "  0.5020156502723694,\n",
       "  0.5007761716842651,\n",
       "  0.5001324415206909,\n",
       "  0.49980995059013367,\n",
       "  0.4996753931045532,\n",
       "  0.4995979070663452,\n",
       "  0.4995635449886322,\n",
       "  0.49956414103507996,\n",
       "  0.4995609223842621,\n",
       "  0.49955299496650696,\n",
       "  0.4995576739311218,\n",
       "  0.4995648264884949,\n",
       "  0.4995633661746979,\n",
       "  0.49955448508262634,\n",
       "  0.49956247210502625,\n",
       "  0.49957385659217834,\n",
       "  0.49955910444259644,\n",
       "  0.49955421686172485,\n",
       "  0.49955713748931885,\n",
       "  0.499571830034256,\n",
       "  0.49956974387168884,\n",
       "  0.4995587468147278,\n",
       "  0.49956467747688293,\n",
       "  0.4995606541633606,\n",
       "  0.49956148862838745,\n",
       "  0.4995567202568054,\n",
       "  0.4995686113834381,\n",
       "  0.4995625913143158,\n",
       "  0.4995672106742859,\n",
       "  0.499568372964859,\n",
       "  0.49956825375556946,\n",
       "  0.49956247210502625,\n",
       "  0.4995588958263397,\n",
       "  0.4995560646057129,\n",
       "  0.49956583976745605,\n",
       "  0.4995567798614502,\n",
       "  0.4995618760585785,\n",
       "  0.49956491589546204,\n",
       "  0.4995726943016052,\n",
       "  0.49956241250038147,\n",
       "  0.49956196546554565,\n",
       "  0.4995603859424591,\n",
       "  0.49956297874450684,\n",
       "  0.4995559751987457,\n",
       "  0.4995780885219574,\n",
       "  0.49955883622169495,\n",
       "  0.49956318736076355,\n",
       "  0.49958616495132446,\n",
       "  0.49955248832702637,\n",
       "  0.4995529353618622,\n",
       "  0.49957385659217834,\n",
       "  0.4995647072792053,\n",
       "  0.49955224990844727,\n",
       "  0.49956318736076355,\n",
       "  0.4995726943016052,\n",
       "  0.49955904483795166,\n",
       "  0.4995553195476532,\n",
       "  0.4995594322681427,\n",
       "  0.4995560348033905,\n",
       "  0.4995662271976471,\n",
       "  0.4995597302913666,\n",
       "  0.4995686709880829,\n",
       "  0.49956291913986206,\n",
       "  0.49957436323165894,\n",
       "  0.4995550513267517,\n",
       "  0.4995630085468292,\n",
       "  0.499568372964859,\n",
       "  0.49956971406936646,\n",
       "  0.49956053495407104,\n",
       "  0.4995705783367157,\n",
       "  0.49956533312797546,\n",
       "  0.49956515431404114,\n",
       "  0.49955669045448303,\n",
       "  0.4995589554309845,\n",
       "  0.4995758533477783,\n",
       "  0.49955815076828003,\n",
       "  0.49956953525543213,\n",
       "  0.4995701014995575,\n",
       "  0.49956777691841125,\n",
       "  0.49956151843070984,\n",
       "  0.49955564737319946,\n",
       "  0.4995743930339813,\n",
       "  0.49957242608070374,\n",
       "  0.49955037236213684,\n",
       "  0.49956032633781433,\n",
       "  0.49956655502319336,\n",
       "  0.4995783269405365,\n",
       "  0.49957218766212463,\n",
       "  0.49955567717552185,\n",
       "  0.4995633065700531,\n",
       "  0.49957770109176636,\n",
       "  0.49955281615257263]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# History shows entire loss\n",
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this in a graph for better visualization \n",
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
