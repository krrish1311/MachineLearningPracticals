{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we have to create a model for churn ratio. \n",
    "# Which factor depends on the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "y=df[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Gender & Geography for now to do one hot encoding \n",
    "X=df.drop(['Exited','RowNumber','CustomerId','Surname','Gender','Geography'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  \n",
       "0               1        101348.88  \n",
       "1               1        112542.58  \n",
       "2               0        113931.57  \n",
       "3               0         93826.63  \n",
       "4               1         79084.10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, Geography nd Gender are categorical variable, so do one hot encoding \n",
    "geo=df['Geography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to remove one column for preventing dummy variable trap. \n",
    "geo = pd.get_dummies(geo,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding --> Gender variable\n",
    "gen=df[\"Gender\"]\n",
    "gen = pd.get_dummies(gen,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "9995     1\n",
       "9996     1\n",
       "9997     0\n",
       "9998     1\n",
       "9999     0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now concatenating gender, geography and x\n",
    "X_final=pd.concat([X,gen,geo],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Male  Germany  Spain  \n",
       "0                  1        101348.88     0        0      0  \n",
       "1                  1        112542.58     0        0      1  \n",
       "2                  0        113931.57     0        0      0  \n",
       "3                  0         93826.63     0        0      0  \n",
       "4                  1         79084.10     0        0      1  \n",
       "...              ...              ...   ...      ...    ...  \n",
       "9995               0         96270.64     1        0      0  \n",
       "9996               1        101699.77     1        0      0  \n",
       "9997               1         42085.58     0        0      0  \n",
       "9998               0         92888.52     1        1      0  \n",
       "9999               0         38190.78     0        0      0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split data into training and testing \n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train,X_test,y_train,y_test=tts(X_final,y,test_size=0.2,random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Keras model \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1st layer with 8 neurons\n",
    "# We have 11 features to be provided so input_dim=11\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8, input_dim=11, activation=\"relu\", kernel_initializer=\"zeros\", bias_initializer=\"zeros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd layer \n",
    "model.add(Dense(units=8, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add final layer with sigmoid function as output can be 1 or 0\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt=Adam(learning_rate=0.0000000005)\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 35s 3ms/step - loss: 0.6762\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6189\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5791\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5531\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5325\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5139\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5130\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5010\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5089\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4939\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4979\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5092\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5116\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5004\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4840\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5029\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5002\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5084\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5050\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4844\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4973\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4923\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4980\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4963\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4922\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5014\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4961\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5044\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4992\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5017\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5032\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4916\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5034\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5059\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5048\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4983\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4949\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5005\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5021\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4963\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5045\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5053\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4984\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4928\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4967\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4964\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5039\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4979\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4985\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5074\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4911\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5026\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4986\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4938\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4966\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4962\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4923\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4938\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4958\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5035\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5128\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5052\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4920\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5017\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5049\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5006\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5026\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5039\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5015\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4984\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5064\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5013\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4897\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5113\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4907\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5028\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5038\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4913\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5038\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4995\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5026\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5016\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4841\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4880\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5084\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4988\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5000\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5055\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4902\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4996\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5062\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5100\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4930\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4966\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5002\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5043\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4959\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4957\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4856\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x194c0217df0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just by adding Learning Rate, we can see sudden change in loss. \n",
    "model.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6606464385986328,\n",
       "  0.6069585680961609,\n",
       "  0.5690436363220215,\n",
       "  0.5431583523750305,\n",
       "  0.5260711908340454,\n",
       "  0.5151845812797546,\n",
       "  0.5083867907524109,\n",
       "  0.5043462514877319,\n",
       "  0.5020348429679871,\n",
       "  0.5007903575897217,\n",
       "  0.5001435279846191,\n",
       "  0.4998033940792084,\n",
       "  0.499660849571228,\n",
       "  0.4995936453342438,\n",
       "  0.4995768070220947,\n",
       "  0.4995652735233307,\n",
       "  0.49956509470939636,\n",
       "  0.4995720684528351,\n",
       "  0.4995677173137665,\n",
       "  0.49957484006881714,\n",
       "  0.4995749890804291,\n",
       "  0.4995582103729248,\n",
       "  0.4995690882205963,\n",
       "  0.49957069754600525,\n",
       "  0.49956318736076355,\n",
       "  0.4995615482330322,\n",
       "  0.49955955147743225,\n",
       "  0.4995560646057129,\n",
       "  0.49955716729164124,\n",
       "  0.4995618760585785,\n",
       "  0.4995534420013428,\n",
       "  0.49956515431404114,\n",
       "  0.4995660185813904,\n",
       "  0.4995816946029663,\n",
       "  0.49957510828971863,\n",
       "  0.49956512451171875,\n",
       "  0.49957263469696045,\n",
       "  0.4995647370815277,\n",
       "  0.49955499172210693,\n",
       "  0.49955734610557556,\n",
       "  0.49956488609313965,\n",
       "  0.49956491589546204,\n",
       "  0.499555379152298,\n",
       "  0.4995601177215576,\n",
       "  0.49957549571990967,\n",
       "  0.4995635151863098,\n",
       "  0.49956214427948,\n",
       "  0.49957141280174255,\n",
       "  0.4995655417442322,\n",
       "  0.49955466389656067,\n",
       "  0.4995597302913666,\n",
       "  0.49957573413848877,\n",
       "  0.49955499172210693,\n",
       "  0.4995594322681427,\n",
       "  0.4995558559894562,\n",
       "  0.4995562732219696,\n",
       "  0.4995638132095337,\n",
       "  0.49956032633781433,\n",
       "  0.4995576739311218,\n",
       "  0.49955329298973083,\n",
       "  0.499571293592453,\n",
       "  0.4995623230934143,\n",
       "  0.4995838403701782,\n",
       "  0.49957966804504395,\n",
       "  0.4995657205581665,\n",
       "  0.4995596706867218,\n",
       "  0.49955734610557556,\n",
       "  0.4995729625225067,\n",
       "  0.49956128001213074,\n",
       "  0.49955323338508606,\n",
       "  0.49957045912742615,\n",
       "  0.49956393241882324,\n",
       "  0.4995599687099457,\n",
       "  0.49956101179122925,\n",
       "  0.49956947565078735,\n",
       "  0.4995667338371277,\n",
       "  0.49956369400024414,\n",
       "  0.49958115816116333,\n",
       "  0.49957168102264404,\n",
       "  0.4995778799057007,\n",
       "  0.49956369400024414,\n",
       "  0.49956467747688293,\n",
       "  0.49956202507019043,\n",
       "  0.4995669722557068,\n",
       "  0.4995740056037903,\n",
       "  0.4995635449886322,\n",
       "  0.49957048892974854,\n",
       "  0.49955618381500244,\n",
       "  0.4995744526386261,\n",
       "  0.49956458806991577,\n",
       "  0.4995630383491516,\n",
       "  0.49955278635025024,\n",
       "  0.49956846237182617,\n",
       "  0.49956825375556946,\n",
       "  0.4995672404766083,\n",
       "  0.49955445528030396,\n",
       "  0.4995819926261902,\n",
       "  0.4995526671409607,\n",
       "  0.499568909406662,\n",
       "  0.49956828355789185]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# History shows entire loss\n",
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this in a graph for better visualization \n",
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c14c5ee82961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
